{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"30\" >Practical 05 - Computer Vision</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to thank Peter Corke. The notebook was adapted from P. Corke's RVSS Tutorial material. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"20\" >Homogeneous Coordinates</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import some modules. We will use the standard `numpy` package to help us with linear algebraic operations on matrices and vectors.\n",
    "\n",
    "If you want to know what a function does, just click somewhere within the parentheses that enclose the arguments and hit SHIFT+TAB. If there's a + button at the top of the popup tooltip, this means the documentation spans a few lines, click it to show the full docstring, then scroll up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os.path\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "sys.path.append(\"common\") # common stuff\n",
    "\n",
    "from common import *\n",
    "from cam_visualizers import *\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D, art3d\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection of two lines in the Euclidean plane\n",
    "Now consider two lines: $y = x-2$, and also $y = -2x+6$.\n",
    "They can be represented in homogeneous form as 3-tuples\n",
    "\\begin{align}\n",
    "\\ell_1 &= \\begin{pmatrix}1 & -1 & -2\\end{pmatrix} \\\\\n",
    "\\ell_2 &= \\begin{pmatrix}-2 & -1 & 6\\end{pmatrix}\n",
    "\\end{align}\n",
    "In python this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1 = np.array([1, -1, -2])\n",
    "l2 = np.array([-2, -1, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intersection point of the two lines is the homogeneous point given by the cross product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = np.cross(l1, l2)\n",
    "# We need to convert homogeneous point back to Eculidean point \n",
    "x, y = p[0]/p[2], p[1]/p[2]\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1 = np.array([1, -1, -2])\n",
    "l2 = np.array([-2, -1, 6])\n",
    "p = np.cross(l1, l2)\n",
    "x, y = p[0]/p[2], p[1]/p[2]\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the lines for x=[0,4]\n",
    "x = np.linspace(0, 4, 100)\n",
    "plt.plot(x, x-2, 'r')\n",
    "plt.plot(x, -2*x+6, 'b')\n",
    "\n",
    "# plot the point, first of all convert from homogeneous to Euclidean\n",
    "pe = p[0:2] / p[2]\n",
    "print(pe)\n",
    "plt.plot(pe[0], pe[1], 'ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel lines\n",
    "Consider two parallel lines $y=x$ and $y=x+1$ which in homogeneous form are\n",
    "\\begin{align}\n",
    "\\ell_1 &= \\begin{pmatrix} 1 & -1 & 0\\end{pmatrix} \\\\\n",
    "\\ell_2 &= \\begin{pmatrix} 1 & -1 & 1\\end{pmatrix}\n",
    "\\end{align}\n",
    "then their intersection would be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1 = np.array([1, -1, 0])\n",
    "l2 = np.array([1, -1, 1])\n",
    "p = np.cross(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we see has its third element equal to zero. This is an ideal point or a point at infinity.  Bottom line, two parallel lines intersect at infinity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux Question (1pt)\n",
    "What is the intersection point of the following 2 lines? l1 and l2\n",
    "are represented by 2 tuples which are (1, -1, -2) and (1, 1, 1) respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "      <td><div align=\"left\"><font size=\"20\" >Central camera projection model </font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to define a camera model\n",
    "\n",
    "Let's first define some parameters of our camera:\n",
    "- ``f``: focal length in metres\n",
    "- ``rho``: pixel side length in metres\n",
    "- ``u0``: principal point, horizontal coordinate\n",
    "- ``v0``: principal point, vertical coordinate\n",
    "\n",
    "\n",
    "Next we define some matrices:\n",
    "- A 3x3 **intrinsic matrix** (``intrinsic_mat``) that contains information about the camera itself:\n",
    "  - focal length of the lens\n",
    "  - pixel size\n",
    "  - the position of the principal point in units of pixels,this is where the _principal ray_ pierces the image plane.\n",
    "  \n",
    "- A 3x4 **projection matrix** (``proj_mat``) that converts 3D world points to 2D image plane points\n",
    "\n",
    "- A 4x4 **extrinsic matrix** (``extrinsic_mat``) defines how the camera is positioned and oriented in space. We use an identity matrix to place our camera at the world frame origin and looking along the world z-axis.\n",
    "\n",
    "Finally, we multiply these three matrices together to form the camera matrix (``camera_mat``) of dimensions 3x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -------------------- Camera Parameters ---------------------\n",
    "\n",
    "f = 8*1e-3     # focal length in metres\n",
    "rho = 10*1e-6  # pixel side length in metres\n",
    "u0 = 500       # principal point, horizontal coordinate\n",
    "v0 = 500       # principal point, vertical coordinate\n",
    "\n",
    "# ----------------------- Matrices -------------------------\n",
    "\n",
    "intrinsic_mat = np.array([  [f/rho, 0,     u0], \n",
    "                [0,     f/rho, v0], \n",
    "                [0,     0,     1]])\n",
    "\n",
    "proj_mat = np.array([[1, 0, 0, 0],\n",
    "                     [0, 1, 0, 0],\n",
    "                     [0, 0, 1, 0]])\n",
    "\n",
    "extrinsic_mat = np.eye(4)\n",
    "camera_mat = intrinsic_mat @ proj_mat @ np.linalg.inv(extrinsic_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert 3D points to 2D image plane points\n",
    "\n",
    "Let's define a set of points in 3D (in homogeneous coordinates) and project them onto the image plane using the camera matrix we just defined.\n",
    "\n",
    "Remember that the projection will return image plane coordinates in homogeneous form. We need to convert each point to Euclidean coordinates, that is, the 2D image plane coordinates in units of pixels. \n",
    "\n",
    "\n",
    "## Convert 2D points homogeneous form to Euclidean coordinates\n",
    "\n",
    "We can use the helper function ``h2e(.)`` to do so. This function expectes 2D points in homogeneous form and return 2D points Euclidean coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "points_3d = np.array([[-1, 0, 5, 1],\n",
    "                     [ 1, 0, 5, 1],\n",
    "                     [ 0, math.sqrt(3), 5, 1]]).T\n",
    "\n",
    "points_2d = camera_mat @ points_3d\n",
    "\n",
    "points_pixels = h2e(points_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualise these points both in 3D space and in the camera plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We create a camera object. This object will help us to plot our camera\n",
    "camera = Camera(f, rho, (u0, v0))\n",
    "\n",
    "# We set up the 3D space and 2D plane for camera view\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 3D space\n",
    "ax3d = fig.add_subplot(121, projection='3d')\n",
    "ax3d.set_xlabel('X Label')\n",
    "ax3d.set_ylabel('Y Label')\n",
    "ax3d.set_zlabel('Z Label')\n",
    "ax3d.set_title('World View')\n",
    "ax3d.set_xlim(-2,2)\n",
    "ax3d.set_ylim(0,4)\n",
    "\n",
    "# 2 plane\n",
    "ax2d = fig.add_subplot(122)\n",
    "ax2d.set_xlabel('u (pixels)')\n",
    "ax2d.set_ylabel('v (pixels)')\n",
    "ax2d.set_title('Camera image plane')\n",
    "ax2d.set_aspect('equal')\n",
    "ax2d.set_facecolor('yellow')\n",
    "ax2d.set_xlim(0, 1000)\n",
    "ax2d.set_ylim(1000, 0)  # inverted y-axis\n",
    "ax2d.grid()\n",
    "\n",
    "# We plot the polygon that represents our camera\n",
    "cam_viz = CamVisualizer(camera, f_length=0.5, fb_width=0.05, ft_width=0.5)\n",
    "collection = Poly3DCollection(cam_viz.gen_frustrum_poly(), facecolors=['g', 'r', 'b', 'b'])\n",
    "ax3d.add_collection3d(collection)\n",
    "\n",
    "# Draw points in 3d model\n",
    "scat3d = ax3d.scatter(points_3d[0], points_3d[1], points_3d[2], c='b')\n",
    "\n",
    "# Draw points in campera plane\n",
    "scat2d = ax2d.scatter(points_pixels[0], points_pixels[1], c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact\n",
    "- Move the 3D points 0.5 meters in each direction, one axis at the time. Observe how their coordinates chage in the camera image plane?\n",
    "\n",
    "### Flux Question (1pt) :  \n",
    "\n",
    "Where do the points move to (left or right) when we move the camera 0.5m in the x-axis direction?\n",
    "\n",
    "*Hint*: Change the top right element of the ``extrinsic_mat`` so as to represent a translation of 0.5m. Recompute the camera matrix project the 3D points onto the camera plane again and see what happens in the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"30\" >Image Processing</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some helper functions to read, ``iread(relative_path_to_image)``, and display an image ``idisp(image_array)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read an image with colors in RGB order for matplotlib\n",
    "def iread(filename):\n",
    "    \"\"\"\n",
    "    This function reads an image. Only images in the \"images\" folder are considered\n",
    "\n",
    "    :param image: str with name of image to be read. \n",
    "    :return: a numpy array of size [image_height, image_width] where each [i,j] corresponds to a pixel in the image.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(cv2.imread(os.path.join('images', filename)), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# plot the image\n",
    "def idisp(image, title='Image', small=False, interaction=False, cmap='gray'):\n",
    "    \"\"\"\n",
    "    This function displays an image\n",
    "\n",
    "    :param image: a numpy array of size [image_height, image_width (each entry corresponds to a pixel in the image)\n",
    "    :param small: boolean variable indicating preferred size for display\n",
    "    :param interaction: boolean variable indicating whether we want to display the pixel coordinate and \n",
    "                        the grey value of the pixel when cursor drifts over the image\n",
    "    :param cmap: str that indicites which the colormap used to map scalar data to colors. Possible options are: gray or RdBu\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    def mouse_move(self, event, image):\n",
    "        if event.inaxes and event.inaxes.get_navigate():\n",
    "            u = int(round(event.xdata))\n",
    "            v = int(round(event.ydata))\n",
    "            self.set_message(\"I[%d, %d] = %d\" % (u, v, image[v,u]))\n",
    "        \n",
    "    if small:\n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "    plt.rcParams['toolbar'] = 'None' \n",
    "\n",
    "    plt.imshow(image, cmap, interpolation='none')\n",
    "    ax = plt.gca()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('u (pixels)')\n",
    "    plt.ylabel('v (pixels)')\n",
    "    \n",
    "    if interaction:\n",
    "        fig.canvas.toolbar._idDrag = fig.canvas.mpl_connect('motion_notify_event', lambda arg: mouse_move(fig.canvas.toolbar, arg, image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images and pixels\n",
    "We will start by loading an image\n",
    "\n",
    "We will use a convenience function to read the image from a PNG format file.  We can load files of different types (with different extensions), eg. `.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = iread('monalisa.png')\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and `image` is a numpy array (a python style matrix) with dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we see has 700 rows and 677 columns.\n",
    "\n",
    "The data itself is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is simply a big table of 8-bit integers which represent brightness of each pixel as a number between 0 (black) and 1 (white).\n",
    "\n",
    "We can display it as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idisp(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The notebook image view is interactive. If you drift your cursor over the image it displays, beneath, the pixel coordinate and the grey value of the pixel.**  \n",
    "\n",
    "You can turn that feature off by clicking the blue button containin the \"power switch\" icon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image smoothing it is best to use a kernel that is isotropic and symmetric such as a 2D Gaussian\n",
    "$$G(u,v) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{u^2+v^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = 5\n",
    "k = range(-w, w+1)\n",
    "sigma = 20\n",
    "[U,V] = np.meshgrid(k, k)\n",
    "kernel = 1/(2*math.pi*sigma**2)*np.exp(-(U**2+V**2)/(2*sigma**2)) # This is our kernel\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(U, V, kernel, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel('U')\n",
    "ax.set_ylabel('V')\n",
    "ax.set_zlabel('K(U,V)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can blur our image with this kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smoothed = cv2.filter2D(image, -1, kernel)\n",
    "idisp(smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux Question (1pt)\n",
    "\n",
    "Increase the sigma value of the kernel to see what effect it has. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this in a single step where we pass in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(image,(11,11), 3, 3)\n",
    "idisp(blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding edges\n",
    "We can use 2D filtering to find edges as well.  This convolution kernel will find vertical edges.  The intuition is that each row of this kernel subtracts the pixel to the left from the pixel to the right, which will give a positive value if the intensity is increasing left to right.\n",
    "<p style=\"border:3px; border-style:solid; border-color:#FF0000; padding: 1em;\">You may often see this filter kernel written with the first and third columns swapped.  The function filter2D performs correlation, not convolution. These are two similar operations but differ in the kernel being transposed.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kernel = np.array( [ [-1, 0, 1],\n",
    "                     [-2, 0, 2],\n",
    "                     [-1, 0, 1] ]) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = iread('penguins.png')\n",
    "idisp(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "edgy = cv2.filter2D(image, cv2.CV_32F, kernel)\n",
    "idisp(edgy, cmap='RdBu')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is displayed with a color map that shows negative numbers as red and positive numbers as blue.  Zoom in on the outline of the \"T\" (use the second button from the right) and you can see that the intensity goes up (blue) on the left of the stem of the \"T\", from the grey background to the white paint. It goes down (red) on right of the stem, from the white paint to the gray background.\n",
    "\n",
    "<p style=\"border:3px; border-style:solid; border-color:#FF0000; padding: 1em;\">Note that we tell filter2D to output a signed floating point image.  The result, at each pixel, can be positive or negative.  By default the output image will be the same as the input image (signalled by the -1 second argument used in previous examples) but that cannot represent negative numbers.  In the land of 8-bit unsigned numbers 6-4=2 but 4-6=0.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux Question (1pt)\n",
    "Write the code of computing horizontal edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><div align=\"left\"><font size=\"10\" >Coding Exercise (6 pts)</font></div></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your own convolution operation with an image you chose (from the images folder) using numpy operations rather than just calling opencv methods. \n",
    "\n",
    "### TODO:\n",
    "\n",
    "To complete this exercise, please fill the missing code in the ``convolve_image(.)`` method. This method has as parameters:\n",
    "- ``image_name (str)``: the name of the image you want to convolve (**make sure to use an image in the images folder or to add any image of your choice to that folder**)\n",
    "- ``my_kernel (np.array)``: 3x3 np.array specifying the convolution kernel to be used\n",
    "\n",
    "You should return a nxm np.array with the convolved image, where n = image width and m = image height.\n",
    "\n",
    "### Keep in mind:\n",
    "\n",
    "- Flip the kernel: Non-symmetric kernels have to be flipped both around its horizontal and vertical axis before calculating the convolution \n",
    "- Pad your image: Add a zero padding to the image being convoluted so you will not run into dimensionality issues.\n",
    "\n",
    "### For grading: \n",
    "- Please make sure that your function receives and returns the expected variables and types. If you change the function's signature, your code will fail to run with the test parameters specified by the grading tool and you will be assigned 0 pts\n",
    "- Do not include any ``print(.)`` statement inside the function being graded\n",
    "- Make sure your code runs. Otherwise, the grading tool will take any execution error as an incorrect answer and you will be assigned 0 pts.\n",
    "- If you do not follow the naming convention **[StudentID]_Practical05.ipynb**, your code will not be graded and  you will be assigned 0 pts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_image(image_name=\"\", my_kernel=None):\n",
    "        \n",
    "    \"\"\"\n",
    "    This function which takes an image_name and a kernel and returns the convolution of them.\n",
    "\n",
    "    :param image: str with name of image to be used for convolution. \n",
    "                  If a name is not provided, a dummy array will be used as image instead\n",
    "    \n",
    "    :param kernel: a numpy array of size [kernel_height, kernel_width].\n",
    "                   If no kernel is provided, a 3x3 identity matrix will be defined as kernel\n",
    "    :return: a numpy array of size [image_height, image_width] (convolution output).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a dummy matrix in case image_name is not provided\n",
    "    image = np.arange(100).reshape(10,10)\n",
    "    \n",
    "    # We read the image\n",
    "    if image_name != \"\":\n",
    "        image = iread(image_name)\n",
    "        \n",
    "    # Define dummy kernel if my_kernel is not provided        \n",
    "    if my_kernel is None:\n",
    "        my_kernel = np.eye(3)\n",
    "        \n",
    "    # convolution output\n",
    "    conv_image = np.zeros_like(image)\n",
    "        \n",
    "    # ------------------------------- Add your code here ----------------------\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "    return conv_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your solution numerically\n",
    "\n",
    "You can verify your implementation numerically by comparing your output with to the test cases provided below. The test cases use the dummy array internally specified by the ``convolve_image(.)`` when no image file name is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test cases from pickle file\n",
    "with open('common/conv_test_cases.pk', 'rb') as my_file:\n",
    "    test_cases = pickle.load(my_file)\n",
    "    \n",
    "# Run each case and compare outputs\n",
    "for i, case in enumerate(test_cases):\n",
    "    # Get kernel used in test case\n",
    "    test_kernel = case['kernel']\n",
    "    # Get expected output\n",
    "    expected_output = case['output']\n",
    "    # Generate output using your implementation\n",
    "    your_output = convolve_image(image_name=\"\", my_kernel=test_kernel)\n",
    "    \n",
    "    \n",
    "    if not np.all(np.isclose(expected_output, your_output)):\n",
    "        print(\"You have failed test case {}/{}. Please revise your implementation\".format(i+1, \n",
    "                                                                                          len(test_cases)))\n",
    "        break\n",
    "    else:\n",
    "        print(\"You have passed test {}/{}\".format(i+1, len(test_cases)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your solution visually\n",
    "\n",
    "You can verify your implementation visually by comparing your output with the one generated by python library **scipy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the kernel we want to use\n",
    "kernel = np.array([[0.,1.,0.], [1.,1.,1.], [0.,1.,0.]])\n",
    "\n",
    "# Specify the image path\n",
    "image_file = 'penguins.png'\n",
    "\n",
    "# Call your function\n",
    "my_result = convolve_image(image_file, kernel)\n",
    "\n",
    "# Display the output\n",
    "idisp(my_result, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use scipy to do the convultion automatically for us\n",
    "\n",
    "# Load the required library\n",
    "from scipy import ndimage\n",
    "\n",
    "# Apply the convolution\n",
    "original_image = iread(image_file)\n",
    "output = ndimage.convolve(original_image, kernel, mode='constant', cval=0.0)\n",
    "\n",
    "# Display the output\n",
    "idisp(output, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntelligentRobotics",
   "language": "python",
   "name": "intelligentrobotics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
