{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5bjAAMSLng-z"
   },
   "source": [
    "# Image classification with Convolutional NN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEKpxC92ng-0"
   },
   "source": [
    "## Import all the packages required\n",
    "\n",
    "<p style=\"color:#FF0000\";> <b>Important: Set the RUN_TRAINING and FLAG_GPU (see below) flags to False before submitting your notebook</b></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymiz4H-Fng-0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import time for timekeeping\n",
    "import time\n",
    "# io allows reading and writing image from disk\n",
    "# from skimage import io\n",
    "\n",
    "\n",
    "# Pytorch (Our Deep Learning Framework)\n",
    "import torch\n",
    "\n",
    "# Torch Data Loader (this will be helful to load image)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# datasets have mnist if using coustom images import io from skimage\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "# stores different optimizors like SGD\n",
    "import torch.optim as optim\n",
    "\n",
    "# Some torch functions that are used multiple times\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Change this flag if using a CPU. Change this flag before submitting your notebook. Set it to False\n",
    "FLAG_GPU = False\n",
    "\n",
    "# Change this flag before submitting your notebook. Set it to False\n",
    "RUN_TRAINING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqhzwvhSng-4"
   },
   "source": [
    "## Here is the Multi Layer Perceptron definition you saw.\n",
    "* Any network has an * __ init __ * function that initializes all the layers of a NN that require learnable parameters.\n",
    "* A MLP is a stack of fully connected layers. In this example we use three fully connected layers named :''fc0'', ''fc1'' and ''fc2''.\n",
    "* Note that each fully connected layer has a number of input neurons that connect to a number of output neurons. \n",
    "* These input and output dimensions are specified in the fc layer initialization.\n",
    "* If a fully connected layer connects to another, its output size = input size of the fully connected layer that follows.\n",
    "* The number of parameters in any fully connected layer is #Input x #Output (and 1 bias per output).\n",
    "\n",
    "## How do we write a forward function?\n",
    "* torch.flatten(x, start_dim = dim) converts an image-like entity to a vector.\n",
    "* Remeber that you need activations after every fc layer. In this case we use ReLu. \n",
    "* Notice the log_sofmax layer at the end. This is a softmax activation function followed by a log function as the name suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fpwsbw5Ung-4"
   },
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        # First fully connected layers input image is 28x28 = 784 dim.\n",
    "        self.fc0 = nn.Linear(784, 256) # nparam = 784*256 = 38400\n",
    "        # Two more fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flattens the image like structure into vectors\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # fully connected layers with activations\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # Outputs are log(p) so softmax followed by log.\n",
    "        #return(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5UCTg-ang-7"
   },
   "source": [
    "# Our task today is to replace this with a convolutional NN.\n",
    "\n",
    "## The Lecun Net we want to implement should look like the one in this figure:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1200/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "\n",
    "* Our network now has two blocks.  Each of them has the structure 'convolution followed by relu followed by max pooling'.\n",
    "* These two blocks replace the 'fc0' layer and the relu that follows in the example MLP. \n",
    "* Read inline TODO comments to change the model convolution net for training.\n",
    "\n",
    "**Conv2d is a 2D convolutional layer:**\n",
    "   * Initialization reqires the kernal/filter size, number of input channels and number of filters (defining size of output).\n",
    "   * First block has 5x5 convolutional filters. We use 6 of them. Convolutional layer takes a 28x28 image of one channel as input.\n",
    "   * What will be the size after the first 5x5 convolution? Why?\n",
    "   * Second convolution is again 5x5 but this time we use 16 filters as the data we want to encode is more complex.\n",
    "   * Remember to add activation after every convolution!\n",
    "    \n",
    "**MaxPooling2D does subsampling**\n",
    "   * y = F.max_pool2d(x, k) command is used to perform kxk max pooling of some data x to create a smaller y. \n",
    "   * If the input images to pooling are 2Mx2N, then you will get MxN size output.\n",
    "   * We will use 2x2 max pooling after every convolution-relu in this excersise.\n",
    "**We will keep the 'fc1' and 'fc2' from MLP as it is**\n",
    "\n",
    "# Your job here is to put conv-relu-pooling layers in appropriate order to write a forward function.\n",
    "* **Remeber that torch.flatten() converts images to vectors, where will you put the flatten layer now?**\n",
    "* **Think about the number of parameters that you saved by replacing the fc0 of the MLP in this case**\n",
    "\n",
    "# For grading\n",
    "* Do not change the names of the network's attributes (i.e., ``self.conv1, self.conv2, self.fc1, self.fc2``)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7qLeBv3ng-9"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Two convolution layers, I am writing the first one\n",
    "        # First convolutional layer takes single channel images (batch_size specifies the number of images) as input\n",
    "        # We have 5x5 convolutions\n",
    "        # We have 6 convolutional filters to produce output size 6*28*28 for a single training sample.\n",
    "        # structure is : nn.conv2d(number of input channels, number of filters, conv kernal size, stride = 1)\n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: Add another layer called self.conv1, with Nparam 1*6*5*5 = 150 (+ 5 for bias per output).\n",
    "        # Replace None with the correct instantiation call\n",
    "        #################################################################################\n",
    "        self.conv1 = None\n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: Add another layer called self.conv2, 5x5 convolutions 16 filters in total.\n",
    "        # Replace None with the correct instantiation call\n",
    "        #################################################################################\n",
    "        self.conv2 = None\n",
    "        \n",
    "        # Two more fully connected layers arguments (input size, output size)\n",
    "        #################################################################################\n",
    "        # TODO: What is the input and output sizes to fc2?\n",
    "        # Replace None with the correct instantiation call\n",
    "        #################################################################################\n",
    "                \n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        \n",
    "        # 10 outputs are probability of any specific digit present in the image\n",
    "        # All sum to one\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input goes to convolution so no need to flatten the image yet\n",
    "        #################################################################################\n",
    "        # TODO: add a 5x5 convolution block (conv1 followed by activation followed by 2x2 max pooling)\n",
    "        #################################################################################\n",
    "        # use conv1 output = self.conv1(input)\n",
    "        # use relu as activation with syntext: output = F.relu(input)\n",
    "        # use max pooling with syntext:  output = F.max_pool2d(input, pooling kernal size)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: add another 5x5 convolution block (conv2 followed by activation followed by max pooling)  \n",
    "        #################################################################################\n",
    "      \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Think what will be the size of the image now \n",
    "        # if you don't pad images it is actually (4x4x16)\n",
    "       \n",
    "        #################################################################################\n",
    "        # TODO: following upon your understanding regarding the size of the output, \n",
    "        # do you need to adjust the forward function in any way?\n",
    "        #################################################################################\n",
    "       \n",
    "        \n",
    "        # fully connected layers these remains as is\n",
    "        \n",
    "\n",
    "        # return(x)\n",
    "        # Outputs are log(p)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KwdSTKSng_A"
   },
   "source": [
    "# The rest of the code to train can be used as it is.\n",
    "# We initialize the instance of ConvNet insted of MLP and train it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6K2QBCncng_A"
   },
   "source": [
    "## Initializing a instance of the defined network here.\n",
    "* Note that puting a network to GPU is as simple as writing .cuda() at the end of the instance.\n",
    "* Same is true for a variable. In this  notebook the code inside command \"if FLAG_GPU\" shows all the modifications you need to run your code on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cb0SXcg8ng_B",
    "outputId": "e095dc8c-5b79-4ad9-c14e-877981343a45"
   },
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "if FLAG_GPU:\n",
    "    net.cuda()\n",
    "    print(net)\n",
    "else:\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiKAcOLFng_E"
   },
   "source": [
    "## Dataloaders and Transforms.\n",
    "* dataset.MNIST in pytorch has functionality to download and process MNIST data.\n",
    "* dataloader function usually allows for loading parts of training and test data in minibatches.\n",
    "* It can use somple simple transformations implemented in class transforms that assists training. For example normalizing, resizing or cropping images.\n",
    "* Functionality to dataset, transforms and dataloader classes are usually added to suit new data and training proceedure related to the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glQcUmLjng_F"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Training dataset and training loader.\n",
    "trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# Test dataset and loader.\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Yz03F6Eng_H"
   },
   "source": [
    "## Here we see sample usage of loading some MNIST training data.\n",
    "* How does out training minibatch looks?\n",
    "* At times simple visualization and print statements allowes for understanding/debugging effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilcdQ5O7ng_I",
    "outputId": "fca310d7-4ab1-4d37-e18a-25e3a10a05cb"
   },
   "outputs": [],
   "source": [
    "def imshow(img, l):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    print('Labels were:')\n",
    "    print(l.reshape(-1,8).numpy())\n",
    "\n",
    "# Load sample data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print('shape of images', images.shape)\n",
    "\n",
    "# display batch\n",
    "imshow(utils.make_grid(images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmaLYCBSng_L"
   },
   "source": [
    "## Loss function for learning.\n",
    "* NLLLoss: The abbrivation NLL stands for Negetive log likelihood. It is however a bit of misnomer as the log is not included in the loss itself but was part of the network defination above. \n",
    "* NOTE: When you want to get the probability/likelihood of an image being of a perticular class you need to remove the log from the forward function and use simple softmax activation at test time. Alternatively simply use ''exp'' function from torch to invert log and leave the forward function as it is. \n",
    "\n",
    "## Optimizer\n",
    "* pytorch have various optimization rutines (beyond SGD) pre-implemented.\n",
    "* class optim will take care of backpropogation with these different optimizations for learning as long as the network defination with appropriate forward function is written correctly.\n",
    "* Here we just use SGD. with learning rate 0.001 and momentum 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8-wdfe2ng_L"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "if FLAG_GPU:\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cg_RjXlNng_O"
   },
   "source": [
    "## This cell of the notebook is now training a network.\n",
    "\n",
    "* First for loop goes throught the entire data 5 times (We run 5 epochs for our training).\n",
    "* The simple steps for training a NN with pytorch are:\n",
    "    * Load data in minibatches.\n",
    "    * Set gradients for all the network parameters to zero (dont forget this)\n",
    "    * Pass data to the NN using a net.forward() to compute layer by layer output.\n",
    "        * Intermediate outputs can be returned as extra variables in forward function.\n",
    "    * Compute the loss from the output (remember it is defined above).\n",
    "    * Use loss.backword() to compute all the gradients by appropriately applying chain rule! \n",
    "        * It actually know how to differentiate things!!!\n",
    "    * Use optimizer.step() updates weights.\n",
    "    \n",
    "## At the end of every epoch usually we check if NN generalizes.\n",
    "* Generalization is critical in learning.\n",
    "* We evaluate the performance of our NN on new data, for which the NN loss was not minimized.\n",
    "* torch.no_grad() command forces the following code to not keep track of the gradients as for testing we dont need them.\n",
    "* As no gradients are maintained, the code runs faster!\n",
    "* It a very good practice to make use of no_grad function to ensure that we dont accidently minimize loss on the data we are testing the performance on.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0EJQlbqFng_P",
    "outputId": "9095168f-4fb2-4cb3-b96e-eba61c025ae4"
   },
   "outputs": [],
   "source": [
    "if RUN_TRAINING:\n",
    "    for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Simply for time keeping\n",
    "        start_time = time.time()\n",
    "        # Loop over all training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward \n",
    "            if FLAG_GPU:\n",
    "                outputs = net(inputs.cuda())\n",
    "                loss = criterion(outputs, labels.cuda())\n",
    "            else:\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute Gradients\n",
    "            loss.backward()\n",
    "            # BackProp\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 100 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "            # endif\n",
    "        # end for over minibatches epoch finishes\n",
    "        end_time = time.time()\n",
    "\n",
    "        # test the network every epoch on test example\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Test after the epoch finishes (no gradient computation needed)\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                # load images and labels\n",
    "                images, labels = data\n",
    "\n",
    "                if FLAG_GPU:\n",
    "                    outputs = net(images.cuda())\n",
    "                    # note here we take the max of all probability\n",
    "                    _, predicted = torch.max(outputs.cpu(), 1)\n",
    "                else:\n",
    "                    outputs = net(images)\n",
    "                    # note here we take the max of all probability\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "          #end for\n",
    "        #end with\n",
    "        print('Epoch', epoch+1, 'took', end_time-start_time, 'seconds')\n",
    "        print('Accuracy of the network after', epoch+1, 'epochs is' , 100*correct/total)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mROc5g5Dng_R"
   },
   "source": [
    "# For grading\n",
    "* Your convolutional network should be called ``net`` (this is already done in the code provided)\n",
    "* **You will be graded based on the architecture and performance of your network (6 pts max.)**:\n",
    "    - You will receive a total of 3pts if your architecture is correct.\n",
    "    - You will receive 1 pt if the accuracy of your network is less than 60%\n",
    "    - You will receive 2 pts if the accuracy of your network is more than 60%, but less than 95%\n",
    "    - You will receive 3 pts if the accuracy of your network is above 95%\n",
    "* <p style=\"color:#FF0000\";> <b>Important: Set the RUN_TRAINING and FLAG_GPU (they are defined in the first cell of this notebook) flags to False before submitting your notebook</b></p> \n",
    "* Save your trained network and submit it along witht this notebook (your file should be called ``<STUDENT ID>_ConvNet.pt``. \n",
    "* <p style=\"color:#FF0000\";> <b>Important: Do not forget to submit both your notebook and your trained network </b></p>\n",
    "\n",
    "To save your notebook, please execute the code provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"{}_ConvNet.pt\".format('WRITE YOUR STUDENT ID HERE\")\n",
    "torch.save(net.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test if your network has been saved correctly, you can use the code provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of your conv net\n",
    "model = ConvNet()\n",
    "\n",
    "# Load the parameters you saved into the new instance\n",
    "if FLAG_GPU:\n",
    "    device = torch.device('cuda')\n",
    "    model.load_state_dict(torch.load(file_name))\n",
    "    model.to(device)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    model.load_state_dict(torch.load(file_name, map_location=device))    \n",
    "\n",
    "# Set your network in evaluation mode before running inference.\n",
    "model.eval()\n",
    "\n",
    "# Run inference with the new instance\n",
    "# Performance should be the same as observed at the end of the training\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # load images and labels\n",
    "        images, labels = data\n",
    "\n",
    "        if FLAG_GPU:\n",
    "            outputs = net(images.cuda())\n",
    "            # note here we take the max of all probability\n",
    "            _, predicted = torch.max(outputs.cpu(), 1)\n",
    "        else:\n",
    "            outputs = net(images)\n",
    "            # note here we take the max of all probability\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network after is' , 100*correct/total)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LeNetClassificationExcersise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
